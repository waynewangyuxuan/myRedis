{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gaussian Maximum Likelihood\n",
    "\n",
    "##  MLE of a  Gaussian $p_{model}(x|w)$\n",
    "\n",
    "You are given an array of data points called `data`. Your course site plots the negative log-likelihood  function for several candidate hypotheses. Estimate the parameters of the Gaussian $p_{model}$ by  coding an implementation that estimates its optimal parameters (15 points) and explaining what it does (10 points). You are free to use any Gradient-based optimization method you like.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal mean =  6.214285714285714\n",
      "The optimal sigma =  2.425418120907092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = [4, 5, 7, 8, 8, 9, 10, 5, 2, 3, 5, 4, 8, 9]\n",
    "\n",
    "def gradient(params, data):\n",
    "    mu, sigma = params\n",
    "    n = len(data)\n",
    "    d_mu = np.sum((data-mu)/(sigma**2))\n",
    "    d_sigma = ((data-mu)**2).sum()/(sigma**3) - n/sigma\n",
    "    return np.array([-d_mu, -d_sigma])\n",
    "\n",
    "def gradient_descent(data, learning_rate=0.01, max_iter=1000):\n",
    "    mu, sigma = np.mean(data), np.std(data)\n",
    "    params = np.array([mu, sigma])\n",
    "    for i in range(max_iter):\n",
    "        prev_params = params.copy()\n",
    "        grad = gradient(params, data)\n",
    "        params -= learning_rate * grad\n",
    "    return params\n",
    "\n",
    "\n",
    "param = gradient_descent(data)\n",
    "print(\"The optimal mean = \",param[0])\n",
    "print(\"The optimal sigma = \",param[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This program uses log of MLE to estimate the optimized parameters of a poisson distribution that describes the data.\n",
    "\n",
    "First, the log of MLE is given by \n",
    "$ll = -\\frac{n}{2}\\ln{(2\\pi\\sigma^2)} - \\frac{1}{2\\sigma^2}\\sum_{i}^{n}(x_i-\\mu)^2 $.\n",
    "\n",
    "Taking the paritial deriviate of $ll$ with respect to $\\mu$ renders $\\frac{\\partial ll}{\\partial \\mu} = \\frac{1}{\\sigma^2}\\sum_{i}^{n}(x_i-\\mu)$\n",
    "\n",
    "\n",
    "Taking the paritial deriviate of $ll$ with respect to $\\sigma$ renders $\\frac{\\partial ll}{\\partial \\sigma} = \\frac{1}{\\sigma^3}\\sum_{i}^{n}(x_i-\\mu)^2 - \\frac{n}{\\sigma}$\n",
    "\n",
    "The two partial deriviate composes of our gradient. \n",
    "We use the gradient to iteratively update our value for $\\mu$ and $sigma$ by adding the negative of current partial deriviate. In this process, we approach the true $\\mu$ and $sigma$ that maximizes our MLE.\n",
    "\n",
    "Eventually ,the program reaches the $\\mu$ and $sigma$ that represents a Gaussian distribution in which the likelihoood estimation of given data is maximized\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE of a conditional Gaussian $p_{model}(y|x,w)$\n",
    "\n",
    "You are given a problem that involves the relationship between $x$ and $y$. Estimate the parameters of a $p_{model}$ that fit the dataset (x,y) shown below.   You are free to use any Gradient-based optimization method you like.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimized w is \n",
      " [[-2.59159348]\n",
      " [ 1.03638645]]\n",
      "The optimized sigma is \n",
      "  [-66.1719288]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "x = np.array([8, 16, 22, 33, 50, 51])\n",
    "y = np.array([5, 20, 14, 32, 42, 58])\n",
    "\n",
    "#make x 2-d arrays\n",
    "X = x.reshape(x.shape[0],1)\n",
    "poly = PolynomialFeatures(1)\n",
    "X = poly.fit_transform(X)\n",
    "\n",
    "#make y a 2-d array\n",
    "Y = y.reshape(y.shape[0],1)\n",
    "\n",
    "#initialize w\n",
    "w1 = np.array([1.,1.])\n",
    "w1 = w1.reshape(w1.shape[0],1)\n",
    "\n",
    "#gradient of w \n",
    "def gradient_w(w,x,y):\n",
    "    return -1/(x.shape[0]) * x.T.dot(y-x.dot(w))\n",
    "\n",
    "#find the optimized w1 using gradient descent\n",
    "max_iter = 100000\n",
    "learning_rate = 0.001\n",
    "for i in range(100000):\n",
    "    w1 -= learning_rate*gradient_w(w1,X,Y)\n",
    "\n",
    "#alternatively, the closed form solution of ùë§=((ùëã^ùëáùëã)^‚àí1)ùëã^ùëáùë¶ yields the same w\n",
    "w2 = np.array([-5438/2391,822/797])\n",
    "w2 = w.reshape(w.shape[0],1)\n",
    "\n",
    "\n",
    "def gradient_sigma(w,sigma,x,y): \n",
    "    d_sigma_log = -x.shape[0]/sigma + (1/sigma**3)*sum((y-x.dot(w))**2)\n",
    "    return d_sigma_log\n",
    "\n",
    "#using gradient_descent to find optimized sigma\n",
    "def gradient_descent(x, y, w_begin, learning_rate=0.1, max_iter=1000, tol=1e-3):\n",
    "    w = w_begin\n",
    "    sigma = 4.0\n",
    "    for i in range(max_iter):\n",
    "        old_sigma = sigma\n",
    "        d_sigma = gradient_sigma(w,sigma,x,y)\n",
    "        sigma -= learning_rate * d_sigma\n",
    "    return sigma\n",
    "\n",
    "\n",
    "sigma = gradient_descent(X,Y,w1)\n",
    "\n",
    "print('The optimized w is \\n', w1)\n",
    "print('The optimized sigma is \\n ',sigma)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d6993cb2f9ce9a59d5d7380609d9cb5192a9dedd2735a011418ad9e827eb538"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
